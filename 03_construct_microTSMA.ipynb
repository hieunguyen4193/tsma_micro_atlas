{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35ad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2945 [00:22<1:12:44,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 1_33565332_33565420 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/2945 [00:27<50:49,  1.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 1_39025398_39025500 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2945 [00:28<32:10,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 1_40236200_40236282 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/2945 [00:42<56:23,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 1_6304886_6304981 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/2945 [00:53<1:20:41,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 1_90099597_90099695 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 37/2945 [00:58<59:29,  1.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The region 10_106088688_106088778 only has WBC patterns after filtering, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 77/2945 [02:00<1:14:42,  1.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m full_cover_cpgs \u001b[38;5;241m=\u001b[39m maskdf[maskdf[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     50\u001b[0m df \u001b[38;5;241m=\u001b[39m df[full_cover_cpgs \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethyl_string\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampleID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcover\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABCODE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m---> 51\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_cover_methyl_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfull_cover_cpgs\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# save a list of full covered CpG sites in the region\u001b[39;00m\n\u001b[1;32m     54\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCpG\u001b[39m\u001b[38;5;124m\"\u001b[39m : full_cover_cpgs\n\u001b[1;32m     56\u001b[0m })\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path_to_03_output, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_full_covered_CpGs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py:9196\u001b[0m, in \u001b[0;36mDataFrame.aggregate\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   9193\u001b[0m relabeling, func, columns, order \u001b[38;5;241m=\u001b[39m reconstruct_func(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   9195\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m=\u001b[39mfunc, axis\u001b[38;5;241m=\u001b[39maxis, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 9196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m   9199\u001b[0m     \u001b[38;5;66;03m# This is to keep the order to columns occurrence unchanged, and also\u001b[39;00m\n\u001b[1;32m   9200\u001b[0m     \u001b[38;5;66;03m# keep the order of new columns occurrence unchanged\u001b[39;00m\n\u001b[1;32m   9201\u001b[0m \n\u001b[1;32m   9202\u001b[0m     \u001b[38;5;66;03m# For the return values of reconstruct_func, if relabeling is\u001b[39;00m\n\u001b[1;32m   9203\u001b[0m     \u001b[38;5;66;03m# False, columns and order will be None.\u001b[39;00m\n\u001b[1;32m   9204\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/apply.py:685\u001b[0m, in \u001b[0;36mFrameApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    682\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# TODO: Avoid having to change state\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    688\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py:3634\u001b[0m, in \u001b[0;36mDataFrame.T\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3607\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mT\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   3609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;124;03m    The transpose of the DataFrame.\u001b[39;00m\n\u001b[1;32m   3611\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;124;03m    col2  3  4\u001b[39;00m\n\u001b[1;32m   3633\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py:3574\u001b[0m, in \u001b[0;36mDataFrame.transpose\u001b[0;34m(self, copy, *args)\u001b[0m\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   3572\u001b[0m     new_vals \u001b[38;5;241m=\u001b[39m new_vals\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 3574\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   3576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3578\u001b[0m     result\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    747\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    748\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    749\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py:367\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_object_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    366\u001b[0m     obj_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[0;32m--> 367\u001b[0m     maybe_datetime \u001b[38;5;241m=\u001b[39m [maybe_infer_to_datetimelike(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m obj_columns]\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# don't convert (and copy) the objects if no type inference occurs\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(obj_columns, maybe_datetime)):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/internals/construction.py:367\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_object_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    366\u001b[0m     obj_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[0;32m--> 367\u001b[0m     maybe_datetime \u001b[38;5;241m=\u001b[39m [\u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m obj_columns]\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# don't convert (and copy) the objects if no type inference occurs\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(obj_columns, maybe_datetime)):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:1204\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_datetime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pathlib\n",
    "import random \n",
    "from scipy import optimize\n",
    "\n",
    "inputdir = \"/Volumes/HNWD02/outdir/output_methyl_ReadBased_Models/01_output/TSMA_panel\"\n",
    "path_to_all_fa = \"/Volumes/HNSD01/storage/ref/hg19\"\n",
    "outdir = \"/Volumes/HNSD01/outdir\"\n",
    "outputdir = os.path.join(outdir, \"output_methyl_ReadBased_Models\")\n",
    "path_to_01_output = os.path.join(outputdir, \"01_output\")\n",
    "path_to_02_output = os.path.join(outputdir, \"02_output\")\n",
    "\n",
    "metadata = pd.read_excel(\"/Users/hieunguyen/src/tsma_micro_atlas/metadata/metadata_TSMA_R8281_R8282.xlsx\")\n",
    "\n",
    "# loocv_val_sample = random.sample(metadata.LABCODE.tolist(), 1)[0]\n",
    "\n",
    "region = \"10_104170538_104170638\"\n",
    "loocv_val_sample = \"LAAL31TS\"\n",
    "\n",
    "paneldf = pd.read_excel(\"./assets/12967_2024_5416_MOESM1_ESM.xlsx\")\n",
    "all_regions = paneldf.Region_name.unique()\n",
    "\n",
    "predictiondf = pd.DataFrame()\n",
    "\n",
    "# for region in tqdm(all_regions):\n",
    "path_to_03_output = os.path.join(outputdir, \"03_output\", \n",
    "                                    f\"val_on_{loocv_val_sample}\", \n",
    "                                    \"microAtlas_data\",\n",
    "                                    f\"region_{region}\")\n",
    "os.system(f\"mkdir -p {path_to_03_output}\")\n",
    "df = pd.read_csv(os.path.join(path_to_02_output, f\"{region}_methylString.csv\"), index_col = [0])\n",
    "if loocv_val_sample in df[\"LABCODE\"].unique():   \n",
    "    df_test = df[df[\"LABCODE\"] == loocv_val_sample]\n",
    "    df = df[df[\"LABCODE\"] != loocv_val_sample]\n",
    "\n",
    "    cpg_coords = [item for item in df.columns if item not in \n",
    "    [\"methyl_string\", \"SampleID\",\"cover\",\"LABCODE\",\"TYPE\"] ]\n",
    "\n",
    "    df = df[df[\"cover\"] == df[\"cover\"].max()]\n",
    "\n",
    "    # Filter rows where all cpg_coord columns are either 0 or 1\n",
    "    maskdf = pd.DataFrame()\n",
    "    for c in cpg_coords:\n",
    "        maskdf[c] = [df[df[c].isin([0,1])].shape[0]]\n",
    "    maskdf = maskdf.T.reset_index()\n",
    "    full_cover_cpgs = maskdf[maskdf[0] == df.shape[0]][\"index\"].tolist()\n",
    "    df = df[full_cover_cpgs + [\"methyl_string\", \"SampleID\",\"cover\",\"LABCODE\",\"TYPE\"]]\n",
    "    df[\"full_cover_methyl_string\"] = df[full_cover_cpgs].astype(str).agg(''.join, axis=1)\n",
    "\n",
    "    # save a list of full covered CpG sites in the region\n",
    "    pd.DataFrame({\n",
    "        \"CpG\" : full_cover_cpgs\n",
    "    }).to_csv(os.path.join(path_to_03_output, f\"{region}_full_covered_CpGs.csv\"), index=False)\n",
    "\n",
    "    wbc_patterns = df[df[\"TYPE\"] == \"Control\"].full_cover_methyl_string.unique()\n",
    "\n",
    "    df_nowbc = df[df[\"full_cover_methyl_string\"].isin(wbc_patterns) == False]\n",
    "    if df_nowbc.shape[0] == 0:\n",
    "        tmp_prediction = pd.DataFrame({\n",
    "            \"region\": region,\n",
    "            \"loocv_val_sample\": loocv_val_sample,\n",
    "            \"prediction\": \"WBC\"\n",
    "        }, index=[0])\n",
    "        predictiondf = pd.concat([predictiondf, tmp_prediction], axis=0)\n",
    "        print(f\"The region {region} only has WBC patterns after filtering, skipping...\")\n",
    "        # continue\n",
    "    \n",
    "    # ***** group by samples\n",
    "    dfcount = df_nowbc.groupby([\"SampleID\", \"full_cover_methyl_string\"])[\"TYPE\"].count().reset_index()\n",
    "    dfcount_wide = dfcount.pivot(index='full_cover_methyl_string', columns='SampleID', values='TYPE').fillna(0)\n",
    "    for n in dfcount_wide.columns:\n",
    "        dfcount_wide[n] = dfcount_wide[n]/dfcount_wide[n].sum()\n",
    "\n",
    "    plt.figure(figsize=(25,25))\n",
    "    sns.heatmap(dfcount_wide)# ***** filter out WBC patterns\n",
    "    plt.savefig(os.path.join(path_to_03_output, f\"{region}_methyl_pattern_by_sample_heatmap.pdf\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ***** group by class\n",
    "    toodf = df_nowbc.groupby([\"TYPE\", \"full_cover_methyl_string\"])[\"SampleID\"].count().reset_index().\\\n",
    "        pivot(index='full_cover_methyl_string', columns='TYPE', values='SampleID').fillna(0)\n",
    "    for c in toodf.columns:\n",
    "        toodf[c] = toodf[c]/toodf[c].sum()\n",
    "\n",
    "    toodf = toodf[(toodf != 0).any(axis=1)]\n",
    "    toodf.to_csv(os.path.join(path_to_03_output, f\"{region}_methyl_pattern_by_tissue_type.csv\"), index=True, header=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.heatmap(toodf, square=True, linewidths=0.5, linecolor='gray', cbar_kws={\"shrink\": 0.8})\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_to_03_output, f\"{region}_methyl_pattern_by_tissue_type_heatmap.pdf\"))\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # ***** calculate pairwise cosine similarity between samples\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    # Calculate cosine similarity between all columns of toodf\n",
    "    cosine_sim = cosine_similarity(toodf.T)\n",
    "\n",
    "    # Create a DataFrame with proper labels\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, \n",
    "                                index=toodf.columns, \n",
    "                                columns=toodf.columns)\n",
    "\n",
    "    # Visualize the cosine similarity matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cosine_sim_df, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Cosine Similarity between Tissue Types')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_to_03_output, f\"{region}_cosine_similarity_heatmap.pdf\"))\n",
    "    plt.close()\n",
    "\n",
    "    sum_cos_sim = np.sum(cosine_sim_df.sum().sort_values(ascending=False) - 1)\n",
    "    pd.DataFrame({\"region\": region, \"sum_cosine_similarity\": sum_cos_sim}, index=[0]).to_csv(os.path.join(path_to_03_output, f\"{region}_sum_cosine_similarity.csv\"), index=False)\n",
    "\n",
    "    # micro atlas prediction \n",
    "    df_test = df_test[full_cover_cpgs + [\"methyl_string\", \"SampleID\",\"cover\",\"LABCODE\",\"TYPE\"]]\n",
    "    df_test = df_test[df_test[\"cover\"] == df_test[\"cover\"].max()]\n",
    "    df_test[\"full_cover_methyl_string\"] = df_test[full_cover_cpgs].astype(str).agg(''.join, axis=1)\n",
    "    df_test_nowbc = df_test[df_test[\"full_cover_methyl_string\"].isin(wbc_patterns) == False]\n",
    "\n",
    "    test_countdf = df_test_nowbc.groupby(\"full_cover_methyl_string\")[\"SampleID\"].count().reset_index()\n",
    "    test_countdf[loocv_val_sample] = test_countdf[\"SampleID\"]/test_countdf[\"SampleID\"].sum()\n",
    "    test_countdf = test_countdf.drop(\"SampleID\", axis = 1)\n",
    "\n",
    "    if test_countdf.shape[0] == 0:\n",
    "        test_countdf = pd.DataFrame({\n",
    "            \"full_cover_methyl_string\": toodf.index.tolist(),\n",
    "            loocv_val_sample: 0\n",
    "        })\n",
    "        prediction = \"WBC\"\n",
    "    else:\n",
    "        atlasdf = toodf.merge(test_countdf, on=\"full_cover_methyl_string\", how = \"left\").set_index(\"full_cover_methyl_string\").fillna(0)\n",
    "        if atlasdf[loocv_val_sample].sum() == 0:\n",
    "            prediction = \"WBC\"\n",
    "        else:\n",
    "            mixture, residual = optimize.nnls(atlasdf[[item for item in atlasdf.columns if item != loocv_val_sample]].to_numpy(), \n",
    "                                        atlasdf[loocv_val_sample].to_numpy())\n",
    "            mixture /= np.sum(mixture)\n",
    "            mixturedf = pd.DataFrame({\n",
    "                \"Tissue\": [item for item in atlasdf.columns if item != loocv_val_sample],\n",
    "                \"Proportion\": mixture\n",
    "            })\n",
    "        prediction = mixturedf.loc[mixturedf['Proportion'].idxmax(), 'Tissue']\n",
    "    tmp_prediction = pd.DataFrame({\n",
    "        \"region\": region,\n",
    "        \"loocv_val_sample\": loocv_val_sample,\n",
    "        \"prediction\": prediction\n",
    "    }, index=[0])\n",
    "else:\n",
    "    tmp_prediction = pd.DataFrame({\n",
    "        \"region\": region,\n",
    "        \"loocv_val_sample\": loocv_val_sample,\n",
    "        \"prediction\": \"no data\"\n",
    "    }, index=[0])\n",
    "    print(f\"The sample {loocv_val_sample} not found in region {region}, skipping...\")\n",
    "# predictiondf = pd.concat([predictiondf, tmp_prediction], axis=0)\n",
    "tmp_prediction.to_excel(os.path.join(path_to_03_output, f\"{region}_prediction_on_{loocv_val_sample}.xlsx\"))\n",
    "# predictiondf.to_excel(os.path.join(outputdir, \"03_output\", f\"prediction_on_LOOCV_{loocv_val_sample}.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911d5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[[\"LABCODE\"]].to_csv(\"all_samples.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
